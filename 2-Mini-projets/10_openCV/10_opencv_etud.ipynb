{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1d2a1dcf",
   "metadata": {},
   "source": [
    "# Bibliothèque openCV\n",
    "OpenCV (pour Open Computer Vision) est une bibliothèque graphique libre, initialement développée par Intel, spécialisée dans le traitement d'images en temps réel.\n",
    "Il semble obligatoire que son installation se fasse dans un environnement virtuel créé par l'utilisateur et non pas celui de base."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58c63b4c",
   "metadata": {},
   "source": [
    "#### prérequis : lancer jupyter notebook depuis l'environnement myenv\n",
    "* ouvrir une console anaconda\n",
    "* conda activate myenv\n",
    "* jupyter-notebook.exe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b4d709",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "print(sys.prefix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadddc2d",
   "metadata": {},
   "source": [
    "### Lecture d'une image depuis le disque\n",
    "Utilisation de la fonction __imread__(nom_fichier, option) avec l'option :\n",
    "* cv2.IMREAD_UNCHANGED pour lire des images avec un canal alpha (transparence)\n",
    "* cv2.IMREAD_COLOR pour convertir l'image en 3 canaux de couleurs BGR.\n",
    "* cv2.IMREAD_GRAYSCALE pour convertir l'image en 1 canal de gris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c578bdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge opencv\n",
    "# https://www.delftstack.com/fr/howto/python/conda-install-cv2/\n",
    "# https://www.geeksforgeeks.org/reading-image-opencv-using-python/\n",
    "    \n",
    "# importation du module openCV\n",
    "import cv2\n",
    " \n",
    "# lecture d'une image, img est un numpy ndarray\n",
    "img = cv2.imread(\"lena.png\", cv2.IMREAD_COLOR)\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow(\"lena\", img)\n",
    " \n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "# NE PAS FERMER LA FENETRE GRAPHIQUE \n",
    "cv2.waitKey(0)\n",
    " \n",
    "# OBLIGATOIRE appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8900cb4",
   "metadata": {},
   "source": [
    "### Exercice :\n",
    "Convertir l'image lors de la lecture en niveaux de gris, après lecture. Pour ce faire utiliser la fonction cv2.cvtColor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b9104d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow(\"lena_gray\", img_gray)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# OBLIGATOIRE appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94f166fe-105a-42cb-9039-6446fbd5a6a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on built-in function cvtColor:\n",
      "\n",
      "cvtColor(...)\n",
      "    cvtColor(src, code[, dst[, dstCn]]) -> dst\n",
      "    .   @brief Converts an image from one color space to another.\n",
      "    .\n",
      "    .   The function converts an input image from one color space to another. In case of a transformation\n",
      "    .   to-from RGB color space, the order of the channels should be specified explicitly (RGB or BGR). Note\n",
      "    .   that the default color format in OpenCV is often referred to as RGB but it is actually BGR (the\n",
      "    .   bytes are reversed). So the first byte in a standard (24-bit) color image will be an 8-bit Blue\n",
      "    .   component, the second byte will be Green, and the third byte will be Red. The fourth, fifth, and\n",
      "    .   sixth bytes would then be the second pixel (Blue, then Green, then Red), and so on.\n",
      "    .\n",
      "    .   The conventional ranges for R, G, and B channel values are:\n",
      "    .   -   0 to 255 for CV_8U images\n",
      "    .   -   0 to 65535 for CV_16U images\n",
      "    .   -   0 to 1 for CV_32F images\n",
      "    .\n",
      "    .   In case of linear transformations, the range does not matter. But in case of a non-linear\n",
      "    .   transformation, an input RGB image should be normalized to the proper value range to get the correct\n",
      "    .   results, for example, for RGB \\f$\\rightarrow\\f$ L\\*u\\*v\\* transformation. For example, if you have a\n",
      "    .   32-bit floating-point image directly converted from an 8-bit image without any scaling, then it will\n",
      "    .   have the 0..255 value range instead of 0..1 assumed by the function. So, before calling #cvtColor ,\n",
      "    .   you need first to scale the image down:\n",
      "    .   @code\n",
      "    .       img *= 1./255;\n",
      "    .       cvtColor(img, img, COLOR_BGR2Luv);\n",
      "    .   @endcode\n",
      "    .   If you use #cvtColor with 8-bit images, the conversion will have some information lost. For many\n",
      "    .   applications, this will not be noticeable but it is recommended to use 32-bit images in applications\n",
      "    .   that need the full range of colors or that convert an image before an operation and then convert\n",
      "    .   back.\n",
      "    .\n",
      "    .   If conversion adds the alpha channel, its value will set to the maximum of corresponding channel\n",
      "    .   range: 255 for CV_8U, 65535 for CV_16U, 1 for CV_32F.\n",
      "    .\n",
      "    .   @param src input image: 8-bit unsigned, 16-bit unsigned ( CV_16UC... ), or single-precision\n",
      "    .   floating-point.\n",
      "    .   @param dst output image of the same size and depth as src.\n",
      "    .   @param code color space conversion code (see #ColorConversionCodes).\n",
      "    .   @param dstCn number of channels in the destination image; if the parameter is 0, the number of the\n",
      "    .   channels is derived automatically from src and code.\n",
      "    .\n",
      "    .   @see @ref imgproc_color_conversions\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cv2.cvtColor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf4abd4",
   "metadata": {},
   "source": [
    "### Sauvegarde de l'image\n",
    "Le format de l'image sauvegardée est donné par l'__extension du fichier__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daa6d1e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.imwrite('./image.jpg',img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906e2b64",
   "metadata": {},
   "source": [
    "### Taille de l'image\n",
    "L'image est stockée en mémoire sous la forme d'un tableau numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49509f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "Image Dimension    :  (512, 512, 3)\n",
      "Image Height       :  512\n",
      "Image Width        :  512\n",
      "Number of Channels :  3\n"
     ]
    }
   ],
   "source": [
    "print(type(img))\n",
    "\n",
    "# dimensions de l'image\n",
    "dimensions = img.shape\n",
    " \n",
    "# hauteur, largeur et nombre de channels = bands\n",
    "height = img.shape[0]\n",
    "width = img.shape[1]\n",
    "channels = img.shape[2]\n",
    " \n",
    "print('Image Dimension    : ',dimensions)\n",
    "print('Image Height       : ',height)\n",
    "print('Image Width        : ',width)\n",
    "print('Number of Channels : ',channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c887d8-9d61-44a3-8ec0-1c01716b7c37",
   "metadata": {},
   "source": [
    "### changement de la taille de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62a3ee08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nouvelles dimensions :  (307, 307, 3)\n"
     ]
    }
   ],
   "source": [
    "factor = 0.6 # facteur d'échelle par rapport à l'image originelle\n",
    "width  = int(img.shape[1] * factor)\n",
    "height = int(img.shape[0] * factor)\n",
    "dim = (width, height)\n",
    "  \n",
    "# image redim\n",
    "img_redim = cv2.resize(img, dim, interpolation = cv2.INTER_AREA)\n",
    " \n",
    "print('Nouvelles dimensions : ', img_redim.shape)\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow(\"image \", img_redim)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d52e5f",
   "metadata": {},
   "source": [
    "### exercice : \n",
    "Reprendre le code précédent et changer le rapport d'aspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1595517-1a73-42be-b118-a8455827088a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A COMPLETER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e81f4c5-468b-48e0-8721-b5387f53c912",
   "metadata": {},
   "source": [
    "### Flip de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2687443b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#flip vertical, horizontal et les deux\n",
    "flip_v, flip_h, flip_hv = (0, 1, -1)\n",
    "\n",
    "img_flip = cv2.flip(img, flip_h)\n",
    "cv2.imshow(\"flip \", img_flip)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc78ca7",
   "metadata": {},
   "source": [
    "### Transformation affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a615a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n",
      "Matrice de rotation : \n",
      " [[  0.49497475   0.49497475   2.57292962]\n",
      " [ -0.49497475   0.49497475 256.        ]]\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "import numpy as np\n",
    "\n",
    "# taille de l'image en pixels.\n",
    "(rows, cols) = img.shape[:2]\n",
    "print((rows, cols)) \n",
    "\n",
    "# Matrice de transformation affine : rotation + translation\n",
    "A45=np.ndarray(shape=(2, 3), dtype='float')\n",
    "theta=pi/4.;\n",
    "A45[0] = [ cos(theta), sin(theta), 0]\n",
    "A45[1] = [-sin(theta), cos(theta), 0]\n",
    "\n",
    "img_rot45 = cv2.warpAffine(img, A45, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"Manuel rot45 \", img_rot45)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    "\n",
    "# getRotationMatrix2D cree une matrice de rotation \n",
    "# parametres sont les coords du centre tuple, l'angle en degres, l'échelle \n",
    "A45 = cv2.getRotationMatrix2D((cols / 2, rows / 2), 45, 0.7)\n",
    "\n",
    "print('Matrice de rotation : \\n', A45)\n",
    "img_rot45 = cv2.warpAffine(img, A45, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"rot45 \", img_rot45)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac46402",
   "metadata": {},
   "source": [
    "### Translation de l'image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0ce6780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 512)\n"
     ]
    }
   ],
   "source": [
    "from math import *\n",
    "\n",
    "# taille de l'image en pixels.\n",
    "(rows, cols) = img.shape[:2]\n",
    "print((rows, cols)) \n",
    "\n",
    "# Matrice de transformation affine : rotation + translation\n",
    "T=np.array([[1, 0, cols/2], \n",
    "            [0, 1, 0     ]], dtype='float')\n",
    "\n",
    "img_tr = cv2.warpAffine(img, T, (cols, rows))\n",
    "\n",
    "cv2.imshow(\"Translation \", img_tr)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6259575b",
   "metadata": {},
   "source": [
    "## Opérations arithmétiques sur des images avec OpenCV\n",
    "Les opérations arithmétiques comme l'addition, la soustraction et les opérations par bit (AND, OR, NOT, XOR) peuvent être appliquées aux images d'entrée. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e25717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "    \n",
    "# cv2.addWeighted is applied over the\n",
    "# image inputs with applied parameters\n",
    "weightedSum = cv2.addWeighted(img, 0.6, img_flip, 0.4, 0)\n",
    " \n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow('Weighted Image', weightedSum)\n",
    " \n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b34e17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis = np.concatenate((img, img_flip), axis=1)\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow('Weighted Image', vis)\n",
    " \n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f059f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = cv2.subtract(img_flip, img)\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow('Weighted Image', sub)\n",
    " \n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45dc3209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bitwise AND de 2 images\n",
    "import cv2\n",
    "import numpy as np\n",
    "    \n",
    "#lecture des images\n",
    "img1 = cv2.imread('image1.png') \n",
    "img2 = cv2.imread('image2.png')\n",
    " \n",
    "# cv2.bitwise_and pour appliquer un ET logique sur chaque paire de pixels : blanc = 255, noir = 0\n",
    "dest_and = cv2.bitwise_and(img2, img1, mask = None)\n",
    " \n",
    "vis = np.concatenate((img1, img2, dest_and), axis=0)\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow('Bitwise And', vis)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d249b668",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d77059b",
   "metadata": {},
   "source": [
    "### Exercice :\n",
    "faire de même avec les opérateurs bit à bit __OR__ et __XOR__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2af276d",
   "metadata": {},
   "source": [
    "# Détection des contours\n",
    "\n",
    "Le détecteur d'arêtes de Canny est un opérateur de détection d'arêtes qui utilise un algorithme à plusieurs étapes pour détecter un large éventail d'arêtes dans les images. Il a été développé par John F. Canny en 1986. Canny a également produit une théorie computationnelle de la détection des contours expliquant pourquoi la technique fonctionne. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9982a365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Canny edge detection.\n",
    "edges = cv2.Canny(img, 100, 200)\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow('edge', edges)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af2390c",
   "metadata": {},
   "source": [
    "# equalization = homogénéisation de la distribution de la luminescence\n",
    "Il s'agit d'une méthode qui améliore le contraste d'une image, afin d'étendre la gamme d'intensité.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a49ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#hist = cv.calcHist([img],[0],None,[256],[0,256])\n",
    "\n",
    "hist,bins = np.histogram(img.ravel(),256, (0,256))\n",
    "plt.hist(img.ravel(),256,(0,256)); plt.show()\n",
    "\n",
    "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img_equa = cv2.equalizeHist(img_gray)\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow('equalization', img_equa)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.hist(img_equa.ravel(),256,(0,256)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b812b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_equa = np.ndarray(shape=img.shape, dtype=img.dtype)\n",
    "img_equa[..., 0] = cv2.equalizeHist(img[..., 0])\n",
    "img_equa[..., 1] = cv2.equalizeHist(img[..., 1])\n",
    "img_equa[..., 2] = cv2.equalizeHist(img[..., 2])\n",
    "\n",
    "# affichage dans une fenetre graphique, 1er param : nom de la fenetre, 2e param : image array\n",
    "cv2.imshow('equalization', img_equa)\n",
    "\n",
    "# attente en ms sinon appui d'une touche dans la fenetre graphique\n",
    "cv2.waitKey(0)\n",
    " \n",
    "# appel des destructeurs et desallocation memoire\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "plt.hist(img_equa[..., 0].ravel(),256,(0,256)); plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
